{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a3b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from pathlib import Path\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a65fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(Path(\"data/splited_me_dataset.npz\"), allow_pickle=True)\n",
    "train = dataset['train'].item()\n",
    "dev = dataset['dev'].item()\n",
    "test = dataset['test'].item()\n",
    "unseen_test = dataset['unseen_test'].item()\n",
    "# images = np.load(Path(\"data/images_for_test_episodes.npz\"), allow_pickle=True)['images'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baaefbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_numbers = {}\n",
    "image_numbers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27cc8cb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'analysis/train_numbers.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manalysis/train_numbers.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m     total_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'analysis/train_numbers.txt'"
     ]
    }
   ],
   "source": [
    "with open(Path('analysis/train_numbers.txt'), 'w') as f:\n",
    "    print('train')\n",
    "    total_images = 0\n",
    "    total_audio = 0\n",
    "    for w in train:\n",
    "        i = len(train[w]['images'])\n",
    "        e = len(train[w]['english'])\n",
    "        f.write(f'{w}\\t{i}\\t{e}\\n')\n",
    "        total_images += i\n",
    "        total_audio += e\n",
    "        if w not in audio_numbers: audio_numbers[w] = {'type': 'familiar', 'color': 'royalblue', 'count': 0}\n",
    "        audio_numbers[w]['count'] += e\n",
    "        if w not in image_numbers: image_numbers[w] = {'type': 'familiar', 'color': 'royalblue', 'count': 0}\n",
    "        image_numbers[w]['count'] += i\n",
    "    print(total_images, total_audio)\n",
    "        \n",
    "with open(Path('analysis/val_numbers.txt'), 'w') as f:\n",
    "    print('val')\n",
    "    total_images = 0\n",
    "    total_audio = 0\n",
    "    for w in dev:\n",
    "        i = len(dev[w]['images'])\n",
    "        e = len(dev[w]['english'])\n",
    "        f.write(f'{w}\\t{i}\\t{e}\\n')\n",
    "        total_images += i\n",
    "        total_audio += e\n",
    "        audio_numbers[w]['count'] += e\n",
    "        image_numbers[w]['count'] += i\n",
    "    print(total_images, total_audio)\n",
    "        \n",
    "with open(Path('analysis/test_numbers.txt'), 'w') as f:\n",
    "    print('test')\n",
    "    total_images = 0\n",
    "    total_audio = 0\n",
    "    for w in test:\n",
    "        i = len(test[w]['images'])\n",
    "        e = len(test[w]['english'])\n",
    "        f.write(f'{w}\\t{i}\\t{e}\\n')\n",
    "        print(w, i, e)\n",
    "        total_images += i\n",
    "        total_audio += e\n",
    "        audio_numbers[w]['count'] += e\n",
    "        image_numbers[w]['count'] += i\n",
    "\n",
    "    for w in unseen_test:\n",
    "        i = len(unseen_test[w]['images'])\n",
    "        e = len(unseen_test[w]['english'])\n",
    "        f.write(f'{w}\\t{i}\\t{e}\\n')\n",
    "        print(w, i, e)\n",
    "        total_images += i\n",
    "        total_audio += e\n",
    "        if w not in audio_numbers: audio_numbers[w] = {'type': 'novel', 'color': 'forestgreen', 'count': 0}\n",
    "        audio_numbers[w]['count'] += e\n",
    "        if w not in image_numbers: image_numbers[w] = {'type': 'novel', 'color': 'forestgreen', 'count': 0}\n",
    "        image_numbers[w]['count'] += i\n",
    "    print(total_images, total_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_labels = []\n",
    "audio_values = []\n",
    "audio_tag = []\n",
    "audio_colors = []\n",
    "image_labels = []\n",
    "image_values = []\n",
    "image_tag = []\n",
    "image_colors = []\n",
    "scale = 1.0\n",
    "for w in audio_numbers:\n",
    "    print(w, audio_numbers[w]['type'], audio_numbers[w]['count'], image_numbers[w]['count'])\n",
    "\n",
    "    audio_labels.append(w)\n",
    "    audio_values.append(scale*audio_numbers[w]['count'])\n",
    "    audio_tag.append(audio_numbers[w]['type'])\n",
    "    audio_colors.append(audio_numbers[w]['color'])\n",
    "    image_labels.append(w)\n",
    "    image_values.append(scale*image_numbers[w]['count'])\n",
    "    image_tag.append(image_numbers[w]['type'])\n",
    "    image_colors.append(image_numbers[w]['color'])\n",
    "\n",
    "    \n",
    "audio_values = np.asarray(audio_values)\n",
    "image_values = np.asarray(image_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000fbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def legend_without_duplicate_labels(ax):\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    unique = [(h, l) for i, (h, l) in enumerate(zip(handles, labels)) if l not in labels[:i]]\n",
    "    ax.legend(*zip(*unique), fontsize=25, bbox_to_anchor=(0.1,-0.05), ncol=2, frameon=False)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 20))\n",
    "\n",
    "# y1 = np.arange(len(audio_labels))\n",
    "y1 = []\n",
    "for y in range(len(audio_labels)):\n",
    "    if audio_labels[y] == 'dog': scale = 0.5\n",
    "    else: scale = 1.0\n",
    "    ax1.barh(y, scale*audio_values[y], label=audio_tag[y], color=audio_colors[y])\n",
    "    ax1.text(scale*audio_values[y], y, str(audio_values[y]), fontsize=18)\n",
    "    y1.append(y)\n",
    "ax1.set_yticks(y1, audio_labels, fontsize=20)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_title('Number of audio samples per class', fontsize=25)\n",
    "ax1.spines[['right', 'top', 'bottom']].set_visible(False)\n",
    "# for patch,color in zip(ax1.patches,audio_colors):\n",
    "#     patch.set_facecolor(color)\n",
    "\n",
    "    \n",
    "y2 = []\n",
    "for y in range(len(image_labels)):\n",
    "    if audio_labels[y] == 'dog': scale = 0.5\n",
    "    else: scale = 1.0\n",
    "    ax2.barh(y, scale*image_values[y], label=image_tag[y], color=image_colors[y])\n",
    "    ax2.text(scale*image_values[y], y, str(image_values[y]), fontsize=18)\n",
    "    y2.append(y)\n",
    "ax2.set_yticks(y2, image_labels, fontsize=20)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_title('Number of image samples per class', fontsize=25)\n",
    "ax2.spines[['right', 'top', 'bottom']].set_visible(False)\n",
    "legend_without_duplicate_labels(ax2)\n",
    "\n",
    "plt.savefig('number_of_samples_per_class.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07227dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be237f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(unseen_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_image_to_dataset = {}\n",
    "unseen_image_to_dataset = {}\n",
    "\n",
    "category_ids = np.load(Path(\"data/coco_dataset.npz\"), allow_pickle=True)['category_ids'].item()\n",
    "    \n",
    "annot = {}\n",
    "segments_dir = Path('../../Datasets/spokencoco/panoptic_annotations_trainval2017/annotations')\n",
    "for fn in segments_dir.rglob('*.json'):\n",
    "\n",
    "    with open(fn, 'r') as f:\n",
    "        l = json.load(f)\n",
    "    \n",
    "    for entry in l['annotations']:\n",
    "        annot[entry['image_id']] =  []\n",
    "        \n",
    "        for e in entry['segments_info']:\n",
    "            id = e['category_id']\n",
    "            if id in category_ids: annot[entry['image_id']].append(category_ids[id])\n",
    "\n",
    "for fn in segments_dir.rglob(f'*.png'):\n",
    "    a = Path(fn).parent.stem\n",
    "    b = Path(fn).parent.parent.stem\n",
    "    if a != b: continue\n",
    "    num = int(fn.stem)\n",
    "    \n",
    "    for c in annot[num]: \n",
    "        name = f'{c}_masked_{num}'\n",
    "        new_fn = Path(f'data/images/{name}.jpg')\n",
    "        \n",
    "        if c in unseen_test:\n",
    "            if name not in unseen_image_to_dataset: \n",
    "                unseen_image_to_dataset[name] = {\n",
    "                    'dataset':'mscoco',\n",
    "                    'fn': new_fn\n",
    "                }\n",
    "                \n",
    "                \n",
    "        if c in test:\n",
    "\n",
    "            if name not in seen_image_to_dataset: \n",
    "                seen_image_to_dataset[name] = {\n",
    "                    'dataset':'mscoco',\n",
    "                    'fn': new_fn\n",
    "                }\n",
    "            \n",
    "\n",
    "\n",
    "caltech = np.load(Path('data/caltech_101_dataset.npz'), allow_pickle=True)['names'].item()\n",
    "\n",
    "for im in Path('/media/leannenortje/HDD/Datasets/caltech-101/caltech-101/101_ObjectCategories').rglob('*/*.jpg'):\n",
    "    \n",
    "    raw_c = im.parent.stem\n",
    "    \n",
    "    if raw_c in caltech: \n",
    "        c = caltech[raw_c]\n",
    "        num = int(im.stem.split('_')[-1])\n",
    "        name = f'{c}_masked_{num}'\n",
    "        new_fn = Path(f'data/images/{c}_masked_{num}.jpg')\n",
    "        if c == 'bird' and num == 335081: print(raw_c, c, name)\n",
    "\n",
    "        if c in unseen_test: \n",
    "            if name not in unseen_image_to_dataset: \n",
    "                unseen_image_to_dataset[name] = {\n",
    "                    'dataset':'caltech',\n",
    "                    'fn': new_fn\n",
    "                }\n",
    "\n",
    "        elif c in test:\n",
    "            if name not in seen_image_to_dataset: \n",
    "                seen_image_to_dataset[name] = {\n",
    "                    'dataset':'caltech',\n",
    "                    'fn': new_fn\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a118a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in test:\n",
    "    print(c, len(test[c]['images']))\n",
    "    \n",
    "    for im in test[c]['images']:\n",
    "        name = Path(im).stem\n",
    "        if name not in seen_image_to_dataset: print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in images:\n",
    "    print(c, len(images[c]))\n",
    "    \n",
    "    for im in images[c]:\n",
    "        name = Path(im).stem\n",
    "        if name not in unseen_image_to_dataset: print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_counting = {}\n",
    "seen_images = set()\n",
    "\n",
    "for c in test:\n",
    "    \n",
    "    for im in test[c]['images']:\n",
    "        seen_images.add(im)\n",
    "        name = Path(im).stem\n",
    "        \n",
    "        c = name.split('_')[0]\n",
    "        dataset = seen_image_to_dataset[name]['dataset']\n",
    "        if c not in seen_counting: seen_counting[c] = {'mscoco': 0, 'caltech': 0}\n",
    "        seen_counting[c][dataset] += 1\n",
    "    \n",
    "check = 0\n",
    "for c in seen_counting:\n",
    "    caltech = seen_counting[c]['caltech']\n",
    "    mscoco = seen_counting[c]['mscoco']\n",
    "    check += mscoco\n",
    "    check += caltech\n",
    "    print(f'{c} Caltech: {caltech} MSCOCO: {mscoco}')\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9524159",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_counting = {}\n",
    "unseen_images = set()\n",
    "\n",
    "for c in images:\n",
    "\n",
    "    for im in images[c]:\n",
    "        if im in unseen_images: print(im)\n",
    "        unseen_images.add(im)\n",
    "        name = Path(im).stem\n",
    "            \n",
    "\n",
    "        c = name.split('_')[0]\n",
    "        dataset = unseen_image_to_dataset[name]['dataset']\n",
    "        if c not in unseen_counting: unseen_counting[c] = {'mscoco': 0, 'caltech': 0}\n",
    "        unseen_counting[c][dataset] += 1\n",
    "\n",
    "check = 0\n",
    "for c in unseen_counting:\n",
    "    caltech = unseen_counting[c]['caltech']\n",
    "    mscoco = unseen_counting[c]['mscoco']\n",
    "    check += mscoco\n",
    "    check += caltech\n",
    "    print(f'{c} Caltech: {caltech} MSCOCO: {mscoco}')\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2085eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = set()\n",
    "\n",
    "for c in test:\n",
    "    for im in test[c]['images']:\n",
    "        all_images.add(str(im))\n",
    "        \n",
    "for c in images:\n",
    "    for im in images[c]:\n",
    "        all_images.add(str(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e76f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seen_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unseen_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seen_images) + len(unseen_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20125849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
